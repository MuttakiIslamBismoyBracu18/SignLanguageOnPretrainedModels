{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84154508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras-squeezenet\n",
      "  Downloading keras_squeezenet-0.4.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-squeezenet) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-squeezenet) (1.11.1)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-squeezenet) (3.9.0)\n",
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-squeezenet) (2.14.0)\n",
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-squeezenet) (2.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-squeezenet) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-squeezenet) (6.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow->keras-squeezenet) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (4.24.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (68.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2.23.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-squeezenet) (3.2.2)\n",
      "Building wheels for collected packages: keras-squeezenet\n",
      "  Building wheel for keras-squeezenet (setup.py): started\n",
      "  Building wheel for keras-squeezenet (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-squeezenet: filename=keras_squeezenet-0.4-py3-none-any.whl size=3577 sha256=19081aae0e0d67968989519e6b475ea2264561349d936469c7029ed435f7ab37\n",
      "  Stored in directory: c:\\users\\bismoy\\appdata\\local\\pip\\cache\\wheels\\c5\\8b\\bb\\eff0cb7dd0853f712e4ace15fbc569abd6141321ded205abdf\n",
      "Successfully built keras-squeezenet\n",
      "Installing collected packages: keras-squeezenet\n",
      "Successfully installed keras-squeezenet-0.4\n"
     ]
    }
   ],
   "source": [
    "# Install keras_squeezenet\n",
    "!pip install keras-squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f719a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet, VGG16, ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout, Input, Conv2D, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4761136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'E:/Undergrad Research/BanglaDatasetUS/'\n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "models_dir = 'E:/Undergrad Research/BanglaDatasetUS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817d51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the models directory exists\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a890715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data generators\n",
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d586b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5449fbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2304 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae622f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 576 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eb78d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 720 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b2639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create SqueezeNet model manually\n",
    "def SqueezeNet(input_shape=(224, 224, 3), classes=1000):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(96, (7, 7), strides=(2, 2), padding='valid', activation='relu', name='conv1')(input_img)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool1')(x)\n",
    "    \n",
    "    def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "        s_id = 'fire' + str(fire_id) + '/'\n",
    "        x = Conv2D(squeeze, (1, 1), padding='valid', activation='relu', name=s_id + 'squeeze1x1')(x)\n",
    "        left = Conv2D(expand, (1, 1), padding='valid', activation='relu', name=s_id + 'expand1x1')(x)\n",
    "        right = Conv2D(expand, (3, 3), padding='same', activation='relu', name=s_id + 'expand3x3')(x)\n",
    "        x = concatenate([left, right], axis=3, name=s_id + 'concat')\n",
    "        return x\n",
    "\n",
    "    x = fire_module(x, fire_id=2)\n",
    "    x = fire_module(x, fire_id=3)\n",
    "    x = fire_module(x, fire_id=4)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool4')(x)\n",
    "    \n",
    "    x = fire_module(x, fire_id=5)\n",
    "    x = fire_module(x, fire_id=6)\n",
    "    x = fire_module(x, fire_id=7)\n",
    "    x = fire_module(x, fire_id=8)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool8')(x)\n",
    "    \n",
    "    x = fire_module(x, fire_id=9)\n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "    \n",
    "    x = Conv2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Dense(classes, activation='softmax', name='softmax')(x)\n",
    "    \n",
    "    model = Model(input_img, x, name='squeezenet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83ae9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model\n",
    "def create_model(base_model):\n",
    "    base_model.trainable = False  # Freeze the base model initially\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),  # Add dropout to reduce overfitting\n",
    "        Dense(train_generator.num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a28f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models\n",
    "models = {\n",
    "    \"MobileNet\": MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    \"SqueezeNet\": SqueezeNet(input_shape=(224, 224, 3), classes=train_generator.num_classes),\n",
    "    \"VGG16\": VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    \"ResNet50\": ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    \"EfficientNetB0\": EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db3e07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "373ee2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for fine-tuning\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2bf3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MobileNet...\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 399s 6s/step - loss: 1.9455 - accuracy: 0.5234 - val_loss: 0.2805 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 390s 5s/step - loss: 0.3538 - accuracy: 0.9436 - val_loss: 0.0586 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 390s 5s/step - loss: 0.1500 - accuracy: 0.9774 - val_loss: 0.0209 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 390s 5s/step - loss: 0.0871 - accuracy: 0.9909 - val_loss: 0.0143 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 392s 5s/step - loss: 0.0515 - accuracy: 0.9961 - val_loss: 0.0115 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 390s 5s/step - loss: 0.0481 - accuracy: 0.9948 - val_loss: 0.0161 - val_accuracy: 0.9931 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 389s 5s/step - loss: 0.0334 - accuracy: 0.9974 - val_loss: 0.0067 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "27/72 [==========>...................] - ETA: 3:14 - loss: 0.0252 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for model_name, base_model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    if model_name == \"SqueezeNet\":\n",
    "        model = base_model  # Use the manually defined SqueezeNet model directly\n",
    "    else:\n",
    "        model = create_model(base_model)\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model with frozen base layers\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=10,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    if model_name != \"SqueezeNet\":\n",
    "        # Unfreeze some top layers of the base model\n",
    "        base_model.trainable = True\n",
    "        for layer in base_model.layers[:100]:\n",
    "            layer.trainable = False\n",
    "    \n",
    "        # Recompile the model with a lower learning rate for fine-tuning\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "        # Fine-tune the model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=validation_generator,\n",
    "            epochs=10,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_path = os.path.join(models_dir, f'{model_name}.h5')\n",
    "    model.save(model_path)\n",
    "    print(f\"Saved {model_name} model to {model_path}\")\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "    \n",
    "    Y_pred = model.predict(test_generator)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    \n",
    "    print(f\"Classification Report for {model_name}:\")\n",
    "    print(classification_report(test_generator.classes, y_pred, target_names=test_generator.class_indices.keys()))\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": test_acc,\n",
    "        \"Precision\": precision_score(test_generator.classes, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(test_generator.classes, y_pred, average='weighted')\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0394b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "results_df.set_index('Model', inplace=True)\n",
    "results_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Comparison of Pre-trained Models on Alphabet and Number Recognition')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
